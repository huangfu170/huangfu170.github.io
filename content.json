{"posts":[{"title":"简单的介绍","text":"又摸又卷的NLP攻城狮一枚","link":"/2024/10/06/hello-world/"},{"title":"各种loss","text":"Focal Loss for binary classification 12345678910def focal_binary_cross_entropy(logits, targets, gamma=2,alpha=0.5): l = logits.reshape(-1) t = targets.reshape(-1) p = torch.sigmoid(l) p = torch.where(t &gt;= 0.5, p, 1 - p) alpha = torch.where(t &gt;= 0.5, alpha, 1 - alpha) logp = -torch.log(torch.clamp(p, 1e-4, 1 - 1e-4)) loss = logp * ((1 - p) ** gamma) * alpha loss = t.size(-1) * loss.mean() return loss Zlpr Loss 123456789101112131415161718192021def zlpr_loss(logits, target): &quot;&quot;&quot; 多标签分类的交叉熵 说明：y_true和y_pred的shape一致，y_true的元素非0即1， 1表示对应的类为目标类，0表示对应的类为非目标类。 警告：请保证y_pred的值域是全体实数，换言之一般情况下y_pred 不用加激活函数，尤其是不能加sigmoid或者softmax！预测 阶段则输出y_pred大于0的类。如有疑问，请仔细阅读并理解本文。 &quot;&quot;&quot; loss_mask = target != -100 y_true = target.masked_select(loss_mask).view(-1, target.size(-1)) y_pred = logits.masked_select(loss_mask).view(-1, y_true.size(-1)) y_pred = (1 - 2 * y_true) * y_pred y_pred_neg = y_pred - y_true * 1e12 y_pred_pos = y_pred - (1 - y_true) * 1e12 zeros = torch.zeros_like(y_pred[:, :1]) y_pred_neg = torch.cat([y_pred_neg, zeros], dim=-1) y_pred_pos = torch.cat([y_pred_pos, zeros], dim=-1) neg_loss = torch.logsumexp(y_pred_neg, dim=-1) pos_loss = torch.logsumexp(y_pred_pos, dim=-1) return (neg_loss + pos_loss).mean() R-drop loss 1234567891011def r_drop_loss(y_pred: torch.Tensor): &quot;&quot;&quot; 用于R-Drop的损失函数,传入未经sigmoid的logits &quot;&quot;&quot; # y_true = torch.arange(y_pred.shape[0], device=y_pred.device) y_predp,y_predq = y_pred[::2].sigmoid().view(-1).unsqueeze(0).T,y_pred[1::2].sigmoid().view(-1).unsqueeze(0).T y_predp=torch.clamp(y_predp,1e-7,1-1e-7) y_predq=torch.clamp(y_predq,1e-7,1-1e-7) y_predp = torch.cat([y_predp,1-y_predp],dim=1) y_predq = torch.cat([y_predq,1-y_predq],dim=1) SimCSE 1234567891011121314151617181920def simcse_unsup_loss(y_pred,temperature=0.05): &quot;&quot;&quot;无监督的损失函数 y_pred (tensor): bert的输出, [batch_size * 2, 768] &quot;&quot;&quot; # 得到y_pred对应的label, [1, 0, 3, 2, ..., batch_size-1, batch_size-2] y_true = torch.arange(y_pred.shape[0], device=y_pred.device) y_true = (y_true - y_true % 2 * 2) + 1 # batch内两两计算相似度, 得到相似度矩阵(对角矩阵) # [batch_size * 2, 1, 768] * [1, batch_size * 2, 768] = [batch_size * 2, batch_size * 2] sim = F.cosine_similarity(y_pred.unsqueeze(1), y_pred.unsqueeze(0), dim=-1) # 将相似度矩阵对角线置为很小的值, 消除自身的影响 sim = sim - torch.eye(y_pred.shape[0], device=y_pred.device) * 1e12 sim = sim / temperature # 相似度矩阵除以温度系数 # 计算相似度矩阵与y_true的交叉熵损失 loss = F.cross_entropy(sim, y_true) return torch.mean(loss)","link":"/2024/10/06/%E5%90%84%E7%A7%8Dloss/"}],"tags":[{"name":"可能会用到的奇怪东西","slug":"可能会用到的奇怪东西","link":"/tags/%E5%8F%AF%E8%83%BD%E4%BC%9A%E7%94%A8%E5%88%B0%E7%9A%84%E5%A5%87%E6%80%AA%E4%B8%9C%E8%A5%BF/"}],"categories":[],"pages":[]}